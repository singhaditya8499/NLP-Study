{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05a298e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "SEED = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6c0314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/clean_tweet.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3eaa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.text\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c69fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation_test, y_train, y_validation_test = train_test_split(x,y, test_size=0.02, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "944240b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_test, y_validation_test, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a078a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 1564120 with 50.020139119760636% negative and 0.0% positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set has total {len(x_train)} with {len(x_train[y_train==0])*100/(len(x_train)*1.0)}% negative and {len(x_train[y_train==4])*100/(len(x_train)*1.0)}% positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62fbb200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set has total 15960 with 49.454887218045116% negative and 0.0% positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation set has total {len(x_validation)} with {len(x_validation[y_validation==0])*100/(len(x_validation)*1.0)}% negative and {len(x_validation[y_validation==4])*100/(len(x_validation)*1.0)}% positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9157db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has total 15961 with 49.67733851262452% negative and 0.0% positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set has total {len(x_test)} with {len(x_test[y_test==0])*100/(len(x_test)*1.0)}% negative and {len(x_test[y_test==4])*100/(len(x_test)*1.0)}% positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd19c9",
   "metadata": {},
   "source": [
    "### Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19bed5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_tweets_ug(tweets, label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a5149d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([x_train, x_validation, x_test])\n",
    "all_data_w2v = label_tweets_ug(all_data, 'doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6acbbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['your', 'not', 'pregnant', 'oh', 'no', 'what', 'shame'], tags=['doc_288048']),\n",
       " TaggedDocument(words=['cleaning', 'the', 'bathroom'], tags=['doc_357753']),\n",
       " TaggedDocument(words=['feeling', 'left', 'out', 'you', 'never', 'recommend', 'anything', 'to', 'me'], tags=['doc_420123']),\n",
       " TaggedDocument(words=['home', 'sick', 'what', 'the', 'hell', 'wonder', 'if', 'it', 'll', 'mutate', 'into', 'swine', 'flu'], tags=['doc_348643']),\n",
       " TaggedDocument(words=['your', 'tweet', 'reminded', 'me', 'that', 'game', 'was', 'the', 'shit'], tags=['doc_1195630']),\n",
       " TaggedDocument(words=['grumpy', 'cause', 'can', 'not', 'go', 'to', 'move', 'marathong', 'and', 'have', 'to', 'baby', 'sit', 'cleo', 'and', 'aleisha', 'ing', 'hell'], tags=['doc_424869']),\n",
       " TaggedDocument(words=['its', 'some', 'special', 'performance', 'so', 'guess', 'we', 'will', 'not', 'be', 'able', 'to', 'see', 'them', 'perform', 'beatfreaks'], tags=['doc_675535']),\n",
       " TaggedDocument(words=['back', 'at', 'work', 'have', 'not', 'had', 'coffee', 'yet'], tags=['doc_475529']),\n",
       " TaggedDocument(words=['smokin', 'alone', 'in', 'my', 'apartment'], tags=['doc_682421']),\n",
       " TaggedDocument(words=['lost', 'all', 'my', 'audio', 'files', 'for', 'my', 'audio', 'video', 'class', 'hate', 'children'], tags=['doc_434584'])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_w2v[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d93438ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afcd59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4928e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 2448648.27it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ug_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dbow.build_vocab([x for x in tqdm(all_data_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a5a5886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3922507.74it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3925903.10it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3856719.25it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3975301.88it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3911693.83it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 4023467.33it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3997728.99it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3951447.26it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3932928.67it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3854463.08it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3927285.01it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3880443.51it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3937641.04it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3908053.76it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3947195.16it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3963495.89it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3886715.85it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3763341.71it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3960684.23it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3897671.02it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3845290.23it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3933906.30it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3957570.03it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3971368.17it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3841162.03it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3934641.58it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3922266.42it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3713355.40it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3997869.85it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3957179.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_ug_dbow.train(utils.shuffle([x for x in tqdm(all_data_w2v)]), total_examples=len(all_data_w2v), epochs=1)\n",
    "    model_ug_dbow.alpha -= 0.002\n",
    "    model_ug_dbow.min_alpha = model_ug_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa721ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'doc_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43913d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow = get_vectors(model_ug_dbow, x_train, 100)\n",
    "validation_vecs_dbow = get_vectors(model_ug_dbow, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73e09675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425438596491228"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow, y_train)\n",
    "clf.score(validation_vecs_dbow, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fecb0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1596041/1596041 [00:03<00:00, 428314.59it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ug_dmc = Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=2, negative=5, min_count=2, workers=cores,\n",
    "                      alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmc.build_vocab([x for x in tqdm(all_data_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37fa783e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3748590.22it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 2570420.04it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3463299.65it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3723728.71it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3782222.91it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3777487.00it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3642390.97it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3556890.40it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3622820.95it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3633088.23it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3464278.21it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3308955.23it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3241580.14it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3471005.13it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3446538.75it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3626764.09it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3370318.25it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3563259.38it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3647660.37it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3602500.20it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3596620.13it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3474150.30it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3512491.09it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3628828.38it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3615163.36it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3607973.62it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3519321.63it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3842334.94it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3690625.22it/s]\n",
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3352435.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_ug_dmc.train(utils.shuffle([x for x in tqdm(all_data_w2v)]), total_examples=len(all_data_w2v), epochs=1)\n",
    "    model_ug_dmc.alpha -= 0.002\n",
    "    model_ug_dmc.min_alpha = model_ug_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ae70e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmc = get_vectors(model_ug_dmc, x_train, 100)\n",
    "validation_vecs_dmc = get_vectors(model_ug_dmc, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b547c1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6671679197994987"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc, y_train)\n",
    "clf.score(validation_vecs_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60af344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3532870.65it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ug_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=100, window=4, negative=5, min_count=2, workers=cores,\n",
    "                      alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmm.build_vocab([x for x in tqdm(all_data_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9200a767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 1871262.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=0 is 129.57846403121948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3936274.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=1 is 124.09920716285706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3910254.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=2 is 124.15073609352112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3864076.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=3 is 122.7156081199646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3759902.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=4 is 123.7919671535492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3871977.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=5 is 124.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3709326.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=6 is 130.74987506866455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3353492.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=7 is 137.87564396858215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3585618.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=8 is 136.68061089515686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3608699.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=9 is 136.7154939174652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3586682.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=10 is 136.90621399879456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3215399.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=11 is 159.64188885688782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 2777854.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=12 is 159.18491005897522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3182730.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=13 is 167.84329199790955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3640396.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=14 is 125.53525400161743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3962777.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=15 is 122.76637077331543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3829180.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=16 is 123.44796895980835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 2545900.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=17 is 123.48661279678345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3961579.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=18 is 121.94313502311707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3912039.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=19 is 122.63728523254395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3941990.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=20 is 122.76999998092651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3963585.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=21 is 121.97288608551025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3891589.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=22 is 121.68202805519104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3763652.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=23 is 121.571368932724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3812389.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=24 is 121.98173594474792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3845771.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=25 is 122.5416009426117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3894369.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=26 is 122.02499318122864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3864833.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=27 is 124.39642691612244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3686637.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=28 is 122.31435203552246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1596041/1596041 [00:00<00:00, 3876540.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for epoch=29 is 122.42763805389404\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    starttime = time.time()\n",
    "    model_ug_dmm.train(utils.shuffle([x for x in tqdm(all_data_w2v)]), total_examples=len(all_data_w2v), epochs=1)\n",
    "    model_ug_dmm.alpha -= 0.002\n",
    "    model_ug_dmm.min_alpha = model_ug_dmm.alpha\n",
    "    print(f\"Total time taken for epoch={epoch} is {time.time()-starttime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00bd8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmm = get_vectors(model_ug_dmm, x_train, 100)\n",
    "validation_vecs_dmm = get_vectors(model_ug_dmm, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b6741b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6287593984962406"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm, y_train)\n",
    "clf.score(validation_vecs_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f360b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7515037593984962"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_concat_vectors(model1,model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'doc_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix],model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs\n",
    "\n",
    "train_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow,model_ug_dmc, x_train, 200)\n",
    "validation_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow,model_ug_dmc, x_validation, 200)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmc, y_train)\n",
    "clf.score(validation_vecs_dbow_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95fd951e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7432957393483709"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, x_train, 200)\n",
    "validation_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, x_validation, 200)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmm, y_train)\n",
    "clf.score(validation_vecs_dbow_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0012f1f",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6556d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_tweets_bg(tweets, label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(bigram[t.split()], [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37f3e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [t.split() for t in x_train]\n",
    "phrases = Phrases(tokenized_train)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65822860",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_w2v_bg = label_tweets_bg(all_data, 'doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e34b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dbow.build_vocab([x for x in tqdm(all_data_w2v_bg)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_bg_dbow.train(utils.shuffle([x for x in tqdm(all_data_w2v_bg)]), total_examples=len(all_data_w2v_bg), epochs=1)\n",
    "    model_bg_dbow.alpha -= 0.002\n",
    "    model_bg_dbow.min_alpha = model_bg_dbow.alpha\n",
    "    \n",
    "train_vecs_dbow_bg = get_vectors(model_bg_dbow, x_train, 100)\n",
    "validation_vecs_dbow_bg = get_vectors(model_bg_dbow, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_bg, y_train)\n",
    "clf.score(validation_vecs_dbow_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmc = Doc2Vec(dm=1, dm_concat=1, vector_size==100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dmc.build_vocab([x for x in tqdm(all_data_w2v_bg)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_bg_dmc.train(utils.shuffle([x for x in tqdm(all_data_w2v_bgb)]), total_examples=len(all_data_w2v_bg), epochs=1)\n",
    "    model_bg_dmc.alpha -= 0.002\n",
    "    model_bg_dmc.min_alpha = model_bg_dmc.alpha\n",
    "    \n",
    "train_vecs_dmc_bg = get_vectors(model_bg_dmc, x_train, 100)\n",
    "validation_vecs_dmc_bg = get_vectors(model_bg_dmc, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc_bg, y_train)\n",
    "clf.score(validation_vecs_dmc_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=100, window=4, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dmm.build_vocab([x for x in tqdm(all_data_w2v_bg)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_bg_dmm.train(utils.shuffle([x for x in tqdm(all_data_w2v_bg)]), total_examples=len(all_data_w2v_bgb), epochs=1)\n",
    "    model_bg_dmm.alpha -= 0.002\n",
    "    model_bg_dmm.min_alpha = model_bg_dms.alpha\n",
    "    \n",
    "train_vecs_dmm_bg = get_vectors(model_bg_dmm, x_train, 100)\n",
    "validation_vecs_dmm_bg = get_vectors(model_bg_dmm, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm_bg, y_train)\n",
    "clf.score(validation_vecs_dmm_bg, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed64cc",
   "metadata": {},
   "source": [
    "Do the combined modelling and see the result (dbow+dmm and dbow+dmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d64aa699",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_phrases = Phrases(bigram[tokenized_train])\n",
    "trigram = Phraser(tg_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d622f3",
   "metadata": {},
   "source": [
    "Do the same as we did above and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d5d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
