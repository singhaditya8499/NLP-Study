{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da59bc2",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dced6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92145816",
   "metadata": {},
   "source": [
    "### Data exploration and preprocessing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7317e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text is: 1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the text is: {}\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96564507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada553ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(\"\".join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef55feba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is: 65\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print(\"Vocabulary size is: {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b554b",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "There are different ways to tokenize the text. Google uses SentencePiece tokenizer mechanism [Link](https://github.com/google/sentencepiece) that uses subwords to tokenize the sentences. OpenAI which created chatCPT uses tiktoker library developed by them [Link](https://github.com/openai/tiktoken) that uses a BPE (byte-pair encoding) to tokenize.\n",
    "\n",
    "For this work we will be using character level encoding (converting the text to their ASCII equivalent).\n",
    "\n",
    "There is a tradeoff between the encoding numbers (below it is the ASCII codes) and the sequence length generated (a code for every character below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85398a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding for the string \"hi there\" is: [46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "Decoding for the string \"hi there\" is: hii there\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch: i for i,ch in enumerate(chars)}\n",
    "itos = {i: ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "\n",
    "print(\"Encoding for the string \\\"hi there\\\" is: {}\".format(encode(\"hii there\")))\n",
    "print(\"Decoding for the string \\\"hi there\\\" is: {}\".format(decode(encode(\"hii there\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd6838",
   "metadata": {},
   "source": [
    "### Encoding the entire data and using storing them as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b910f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28369d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f25df6",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3706577",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_len = int(0.9 * len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ff05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:train_data_len]\n",
    "val_data = data[train_data_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ed023",
   "metadata": {},
   "source": [
    "### Batch size and batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bcda515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
       "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
       "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
       "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
       "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
       "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
       "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
       "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
       "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
       "        50, 50, 10,  0, 35])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the chunk of data that will be fed to model at once, this might be known as context-length in other cases\n",
    "\n",
    "batch_size = 64 # how many independent sequences will we process in parellel?\n",
    "block_size = 256 # What is the maximum length allowed for prediction?\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "eval_interval = 500\n",
    "max_iters = 5000\n",
    "n_embed = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# if learning rate is lower, number of iterations should be higher\n",
    "lr = 3e-4\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d00bc379",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "# for i,c in enumerate(x):\n",
    "#     print(\"When the context is {}, the most probable next data is {}\".format(x[:i+1], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a684a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of input x and outputs y\n",
    "    data = train_data if split==\"train\" else val_data\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddd32ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs are tensor([[ 0, 26, 53,  ..., 56, 43, 47],\n",
      "        [60, 43, 56,  ..., 56,  1, 41],\n",
      "        [26, 21, 33,  ..., 26, 21, 13],\n",
      "        ...,\n",
      "        [ 5, 57,  1,  ...,  1, 35, 47],\n",
      "        [56, 53, 53,  ..., 59, 50, 42],\n",
      "        [42, 47, 56,  ..., 39, 56,  1]]) with shape torch.Size([64, 256])\n",
      "Outputs are tensor([[26, 53, 58,  ..., 43, 47, 45],\n",
      "        [43, 56,  1,  ...,  1, 41, 53],\n",
      "        [21, 33, 31,  ..., 21, 13, 10],\n",
      "        ...,\n",
      "        [57,  1, 52,  ..., 35, 47, 50],\n",
      "        [53, 53, 58,  ..., 50, 42,  1],\n",
      "        [47, 56, 43,  ..., 56,  1, 51]]) with shape torch.Size([64, 256])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "print(f\"Inputs are {xb} with shape {xb.shape}\")\n",
    "print(f\"Outputs are {yb} with shape {yb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c86a15c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "#         print(f\"When input is {context.tolist()} then most probable output is {target.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65597e",
   "metadata": {},
   "source": [
    "### Baseline mode - Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e9cc609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffdd55661f0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fce90c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb8c6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "\n",
    "        k = self.key(x) # (B,T,16)\n",
    "        q = self.query(x) # (B,T,16)\n",
    "\n",
    "        # compute attention score (\"affinities to other tokens around\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B,T,16) @ (B,16,T) => (B,T,T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T]==0, float('-inf')) # (B,T,T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B,T,T)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # perform the aggrrgation\n",
    "        v = self.value(x) # (B,T,C)\n",
    "\n",
    "        out = wei @ v # (B,T,T) @ (B,T,C) => (B,T,C)\n",
    "\n",
    "        out.shape\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a42de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec5873e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4*n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embed, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f8b412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"Communication followed by computation\"\"\"\n",
    "    def __init__(self,n_embed, n_head):\n",
    "        # n_embed => embedding dimension\n",
    "        # n_head => number of heads we would like\n",
    "        super().__init__()\n",
    "        head_size = n_embed//n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # in original paper, LayerNorm is applied to the output of Multi head attention and FF, but in recent times\n",
    "        # there is slight deviation and it is applied to the input of those components\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4a6b5ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BiGramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # each token directly reads the logits of the next token from lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        # position embedding table\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        # Multiple blocks of self attention head\n",
    "        \n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed) # final layer norm\n",
    "        \n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B,T = idx.shape\n",
    "        \n",
    "        # idx and target are both (B,T) tensors of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C) => (Batch, Time, Channel=n_embed) => (4,8,vocab_size)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        \n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        # cross entropy expects the output as (B, C, T), so we need to reshape\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # we need to crop idx because our embedding size is limited to block size now\n",
    "            idx_cropped = idx[:,-block_size:]\n",
    "            \n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cropped)\n",
    "            # focus only on the last tim step\n",
    "            logits = logits[:,-1,:] # becomes (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # (B,1)\n",
    "            # append sampled index to running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B,T+1)\n",
    "        return idx\n",
    "    \n",
    "model = BiGramLanguageModel()\n",
    "m = model.to(device)\n",
    "# logits, loss = m(xb,yb)\n",
    "# print(logits.shape)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754485a",
   "metadata": {},
   "source": [
    "We can actually predict the log liklihood of the data if we know the vocab size, it is `-ln(1/vocab_size)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3db51",
   "metadata": {},
   "source": [
    "#### Now let us create the model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1926ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab46af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d71bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "KINA:\n",
      "All ding, wis, capt jook, now Cauck van endero,\n",
      "I do ray, how worlo.\n",
      "Way shame\n",
      "Yenching, in gno to bmane that hithafing femiunom:\n",
      "A shilsom god her with I to best no a be made God-make and on morchilve with she fvert thy with my cloan the will do porre a hear with lord Cavilil oplay' a to thou,\n",
      "To salamenoubon.\n",
      "\n",
      "Feredy leav'\n",
      "My maske be have this Rhouresent he hfore in love to thee, no saipt\n",
      "Gents you'ld.\n",
      "\n",
      "Ave him, crouse-sson?\n",
      "What let o you peaces endings\n",
      "te to may with his houst, so; f\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1,1), dtype = torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110cfc9",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe4e89",
   "metadata": {},
   "source": [
    "In the last model we created (Bigram model), there was no way for the character level tokens to talk to their ancestors. They all were generated based on just the previous token. \n",
    "\n",
    "To begin with lets assume that token at `ith` location interacts with all the tokens before that. For this behavior we take the mean of sum of interactions of `ith` element with all the elements before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fe6c2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fce74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1\n",
    "# xbow is x bag of words\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "502e4ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "899d9d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95688ba4",
   "metadata": {},
   "source": [
    "The above method is inefficient as we are doing it in n^2 complexity, we can use matrix multiplication to lower the time complexity. We will use the lower triagular matrix and make it more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6fb677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x\n",
    "# both the torch vectors are same, this is the more efficient way\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64a5f237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f31b0710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4\n",
    "# Self attention !\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape\n",
    "\n",
    "# single head perform self attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B,T,16)\n",
    "q = query(x) # (B,T,16)\n",
    "\n",
    "wei = q @ k.transpose(-2,-1) # (B,T,16) @ (B,16,T) => (B,T,T)\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "\n",
    "# wei is equivalent to the np.dot(Q,K) \n",
    "#wei comes from Q.K_transpose\n",
    "# wei = torch.zeros((T,T))\n",
    "\n",
    "# this line of code prevents future nodes to communicate information to past nodes. If removed every node(token)\n",
    "# will interact with each other. This is removed on the encoder side of the transformers.\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9a27e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01702602",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "1. Attention is a communication mechanism\n",
    "2. There is no notion of space, they are just vectors without any idea of dimension thats why we add positional encoding.\n",
    "3. Every batch is independently trained and they never talk to each other.\n",
    "4. \"Self attention\" - The key, query and value matrix are all coming from the same source.\n",
    "5. \"Cross attention\" - When we pull matrix key and value from different nodes, this is called cross attention.\n",
    "6. If we have unit gaussian input when we set our matrix, the variance of the resultant matrix will be of the order of head_size which is far from when we had started setting the matrix up. If we multiply by sqrt(head_size) then we preserve information. This is important so that the the result after softmax is not sharpened towards the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d2f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
