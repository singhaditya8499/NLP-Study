{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7934325",
   "metadata": {},
   "source": [
    "### POS tagging\n",
    "\n",
    "POS Tagging (Parts of Speech Tagging) is a process to mark up the words in text format for a particular part of a speech based on its definition and context. It is responsible for text reading in a language and assigning some specific token (Parts of Speech) to each word. It is also called grammatical tagging.\n",
    "\n",
    "Source: https://www.guru99.com/pos-tagging-chunking-nltk.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf7ae2",
   "metadata": {},
   "source": [
    "#### Chunking\n",
    "\n",
    "Chunking in NLP is a process to take small pieces of information and group them into large units. The primary use of Chunking is making groups of “noun phrases.” It is used to add structure to the sentence by following POS tagging combined with regular expressions. The resulted group of words are called “chunks.” It is also called shallow parsing.\n",
    "\n",
    "It can be done using `nltk` library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c2614",
   "metadata": {},
   "source": [
    "### How to do Named Entity Recognition?\n",
    "\n",
    "There are two ways to do it:\n",
    "\n",
    "1. Using the nltk library\n",
    "\n",
    "```\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "def extract_ne(trees, labels):\n",
    "    \n",
    "    ne_list = []\n",
    "    for tree in ne_res:\n",
    "        if hasattr(tree, 'label'):\n",
    "            if tree.label() in labels:\n",
    "                ne_list.append(tree)\n",
    "    \n",
    "    return ne_list\n",
    "    \n",
    "# ex is the text\n",
    "            \n",
    "ne_res = ne_chunk(pos_tag(word_tokenize(ex)))\n",
    "labels = ['ORGANIZATION']\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "2. Using spaCy library\n",
    "\n",
    "```\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "wiki_ex = df_wikibooks.iloc[11]['body_text']\n",
    "doc = nlp(wiki_ex)\n",
    "doc\n",
    "\n",
    "print('All entity types that spacy recognised from the document above')\n",
    "set([ent.label_ for ent in doc.ents])\n",
    "\n",
    "print('Persons from the document above')\n",
    "print(set([ent for ent in doc.ents if ent.label_ == 'PERSON']))\n",
    "print('Organizations from the document above')\n",
    "print(set([ent for ent in doc.ents if ent.label_ == 'ORG']))\n",
    "\n",
    "```\n",
    "\n",
    "Source: https://www.kaggle.com/code/eneszvo/ner-named-entity-recognition-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8720f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 12:29:13.842815: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# data is taken from https://www.kaggle.com/competitions/nlp-getting-started/data?select=test.csv\n",
    "# Problem this dataset was for \"Predict which Tweets are about real disasters and which ones are not\"\n",
    "# We are using the dataset to understand NER\n",
    "\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f80368d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../data/tweets_classification_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db2a11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c497e8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Typhoon Soudelor kills 28 in China and Taiwan'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data.iloc[4][\"text\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12aad4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/adityasingh/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.97845435,\n",
       "  'word': 'Soudelor',\n",
       "  'start': 8,\n",
       "  'end': 16},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99978215,\n",
       "  'word': 'China',\n",
       "  'start': 29,\n",
       "  'end': 34},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9997906,\n",
       "  'word': 'Taiwan',\n",
       "  'start': 39,\n",
       "  'end': 45}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"ner\", grouped_entities=True)\n",
    "generator(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd253a1",
   "metadata": {},
   "source": [
    "#### Finetuning a model\n",
    "\n",
    "The process of training a neural network is a difficult and time-consuming process and for most of the users not even feasible. Because of that, instead of training the model from scratch, we can use models from Hugging Face which has been trained using a large amount of text.\n",
    "\n",
    "These types of models through training developed a statistical understanding of the language they have been trained on, but they might not be useful for our specific task. In order to utilize the knowledge of the model, we can apply fine-tuning. It means that we can take pretrained model and train it a little bit more with our annotated data.\n",
    "\n",
    "This process is called transfer learning when the knowledge is transfered from one model to another one and that strategy is often used in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f4260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
